{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn regression with scikit-learn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKzd2bZoI2GfZ4ir/PNhlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linj6669/linj6669_colab/blob/main/learn_regression_with_scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcGs0trxbjC6"
      },
      "source": [
        "# Importing numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Reading the csv file using pandas \n",
        "data = pd.read_csv(\"data/data.csv\")\n",
        "\n",
        "# Extracting dependent and independent variables\n",
        "X = data.drop([\"Target\"],axis=1)\n",
        "y = data[\"Target\"]\n",
        "\n",
        "# Importing splitting method from Scikit-learn (70/30 split)\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=100,\n",
        "                                                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0eUaFT8boZ5"
      },
      "source": [
        "# Fitting a linear model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "# Training our model\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# Taking predictions for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Importing metrics from Scikit-learn\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "# Calculating metrics\n",
        "print(\"The R-squared score is {:.4f}\".format(r2_score(y_test,y_pred)))\n",
        "print(\"The Root Mean Squared error is {:.4f}\".format(np.sqrt(mean_squared_error(y_test,y_pred))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk12V3Pqb4EQ"
      },
      "source": [
        "The model used above explains only 89.78% variance of the dependent variable. This can be improved using more data and better features. Without comparing with other models, we can't infer much using the RMSE value as it is relative to the independent and dependent variables of the simulated dataset.\n",
        "\n",
        "Residuals are prediction errors i.e., difference between the observed value and the predicted value.\n",
        "\n",
        "n6\n",
        "\n",
        "Residuals are used in various performance metrics and can be used to visualize model performance. A resdiuals plot shows residuals on the vertical axis and predicted values on the horizontal axis. In a ideal residuals plot, the distribution of residuals around the target is random and uniformly centered around zero. A good model leads to constant variability in the residuals plot.\n",
        "\n",
        "Let's plot a residual plot. Copy the following code to the editor:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD2JXJeZcETR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Reading the csv file using pandas \n",
        "data = pd.read_csv(\"data/data.csv\")\n",
        "\n",
        "# Extracting dependent and independent variables\n",
        "X = data.drop([\"Target\"],axis=1)\n",
        "y = data[\"Target\"]\n",
        "\n",
        "# Importing splitting method from Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=100,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "# Fitting a linear model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "# Training our model\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# Taking predictions for the test set\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KMuDP0rcO_5"
      },
      "source": [
        "# Residuals plot(overall)\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.scatter(y_pred,y_test-y_pred)\n",
        "plt.title(\"Residuals plot\")\n",
        "plt.xlabel(\"Predicted value\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.savefig(\"res1.png\") # Saving the plot as a PNG file\n",
        "plt.show()\n",
        "\n",
        "# The residuals plot formed by the above code is not randomly or uniformly distributed. In fact, there are some predictions with negative values which is not possible as the dependent variable (bike count) can't be negative.\n",
        "\n",
        "plt.hist(y_test-y_pred, bins= 20)\n",
        "plt.title(\"Histogram of residuals\")\n",
        "plt.savefig(\"res2.png\")\n",
        "plt.show()\n",
        "\n",
        "# The histogram formed by the above code also depicts that the error is not normally distributed around zero and right-skewed. We need a better model as this is not a good fit.\n",
        "\n",
        "# A QQ-plot is formed when quantiles of two variables are plotted against each other. Ideally, all points should lie on or close to the straight line at an angle of 45Â°.\n",
        "\n",
        "# Let's plot a QQ-plot for our model. Statsmodels provides the qqplot_2samples() method to form the QQ-plot. Append the following code to the editor:\n",
        "## Normal QQ-plot\n",
        "from statsmodels.graphics.gofplots import qqplot_2samples\n",
        "qqplot_2samples(y_test,y_pred,line='45')\n",
        "plt.title(\"QQ-plot\")\n",
        "plt.xlabel(\"Quantiles of observed values\")\n",
        "plt.ylabel(\"Quantiles of predicted values\")\n",
        "plt.savefig(\"qq.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}